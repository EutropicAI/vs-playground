{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dfeb4b-effc-4df2-a91b-65f06c28ed92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The yuuno extension is already loaded. To reload it, use:\n",
      "  %reload_ext yuuno\n"
     ]
    }
   ],
   "source": [
    "%load_ext yuuno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c39acf-e5d6-425c-862c-168e00a83eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5a45c9b82d4f3692aa5ca1d385de79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preview(clip=VideoOutputTuple(clip=<vapoursynth.VideoNode object at 0x00007FD574012140 format=YUV420P16, widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%vspreview\n",
    "import vapoursynth as vs\n",
    "from vapoursynth import core\n",
    "from ccrestoration import AutoModel, BaseModelInterface, ConfigType\n",
    "\n",
    "model: BaseModelInterface = AutoModel.from_pretrained(\n",
    "    pretrained_model_name=ConfigType.RealESRGAN_AnimeJaNai_HD_V3_Compact_2x,\n",
    "    tile=None\n",
    ")\n",
    "\n",
    "clip = core.bs.VideoSource(source=\"s.mp4\")\n",
    "clip = core.resize.Bicubic(clip=clip, matrix_in_s=\"709\", format=vs.RGBH)\n",
    "clip = model.inference_video(clip)\n",
    "clip = core.resize.Bicubic(clip=clip, matrix_s=\"709\", format=vs.YUV420P16)\n",
    "clip.set_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f49f10b-5c4f-43ea-8939-ff82a7aaab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a90b421f4ff4bec8f91140d66478ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EncodeWidget(commandline='ffmpeg -i - -vcodec libx265 -crf 16 encoded.mkv', length=3, start_time=1733859048)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%vspipe --y4m | ffmpeg -i - -vcodec libx265 -crf 16 encoded.mkv\n",
    "import vapoursynth as vs\n",
    "from vapoursynth import core\n",
    "from ccrestoration import AutoModel, BaseModelInterface, ConfigType\n",
    "\n",
    "model: BaseModelInterface = AutoModel.from_pretrained(\n",
    "    pretrained_model_name=ConfigType.RealESRGAN_AnimeJaNai_HD_V3_Compact_2x,\n",
    "    tile=None\n",
    ")\n",
    "\n",
    "clip = core.bs.VideoSource(source=\"s.mp4\")\n",
    "clip = core.resize.Bicubic(clip=clip, matrix_in_s=\"709\", format=vs.RGBH)\n",
    "clip = model.inference_video(clip)\n",
    "clip = core.resize.Bicubic(clip=clip, matrix_s=\"709\", format=vs.YUV420P16)\n",
    "clip.set_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
